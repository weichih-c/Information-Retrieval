{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-requirementï¼šTerm generator(i.e., TextProcessor.ipynb)\n",
    "### Calculate a corpus documents' tf-idf vectors.\n",
    "1. If you want to generate the 'dictionary', call 'constructTFIDFVectors' function.\n",
    "2. If you want to calculate two document terms' cosine similarity, call 'cosine' function.\n",
    "\n",
    "### Usage\n",
    "See \"TFIDF_Converter_Example.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run TextPRocessor.ipynb\n",
    "\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicionary_OutputFileName = \"dictionary.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list all files in given directory\n",
    "def listFiles(dir_path):\n",
    "    fList = []\n",
    "    for dirPath, dirName, fileNames in os.walk(dir_path):\n",
    "        fList.extend(fileNames)\n",
    "    return fList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save dictionary list to text file.\n",
    "def saveDictionary(dictionary_list, outputDir):\n",
    "    \n",
    "    with open(outputDir+dicionary_OutputFileName, \"w\") as opf:\n",
    "        \n",
    "        for item in dictionary_list:\n",
    "            index = str(item[0])\n",
    "            term = item[1]\n",
    "            df = str(item[2])\n",
    "            # write to file\n",
    "            opf.write(index+\" \"+term+\" \"+df)\n",
    "            opf.write(\"\\n\")\n",
    "            \n",
    "        opf.close()\n",
    "        \n",
    "    print(\"Generating dictionary done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort the dictionary by term(ascending order)\n",
    "# add the index into tuple\n",
    "\n",
    "def sortDictionary(dictionary_Dict):\n",
    "    tempList = sorted(dictionary_Dict.items(), key = lambda x : x[0])\n",
    "    index = 0\n",
    "    outputList = list()\n",
    "    for item in tempList:\n",
    "        term = item[0]\n",
    "        df = item[1]\n",
    "        outputList.append((index, term, df))\n",
    "        index+=1\n",
    "        \n",
    "    return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for using and efficient purpose, turn the list to dict type\n",
    "def transformDictionaryListToDict(dictionaryList):\n",
    "    outputDict = dict()\n",
    "    for item in dictionaryList:\n",
    "        index = item[0]\n",
    "        term = item[1]\n",
    "        df = item[2]\n",
    "        outputDict[term] = (index, df)\n",
    "    return outputDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate IDF value ( idf = log10(N/df) )\n",
    "def calculateIDF(df, totalDocNumbers):\n",
    "    ratio = totalDocNumbers / df\n",
    "    return math.log10(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVectorLength(vectorTempList):\n",
    "    product = sum(vectorTempList)\n",
    "    return product**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateTFIDF(documentTF_dict, dictionary_dict, totalDocNumbers):\n",
    "    outputDict = dict()\n",
    "    for term, termFrequency in documentTF_dict.items(): # the item is (term: tf)\n",
    "        termObj_in_dictionary =  dictionary_dict[term] # get (term_index,df) tuple\n",
    "        termIndex = termObj_in_dictionary[0] # get term index\n",
    "        df = termObj_in_dictionary[1] # get df\n",
    "        idf = calculateIDF(df, totalDocNumbers)\n",
    "        tfidf = termFrequency * idf # tf-idf = tf * idf\n",
    "        outputDict[termIndex] = tfidf\n",
    "    \n",
    "    # do normalization\n",
    "    vectorTempList = [tfidfValue*tfidfValue for termIdx, tfidfValue in outputDict.items()]\n",
    "    vectorLength = getVectorLength(vectorTempList) # do sum and square root\n",
    "    outputDict = {key: value/vectorLength for key, value in outputDict.items()}\n",
    "    \n",
    "    return outputDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveDocTFIDFInformation(docID, tfidf_info, outputDir):\n",
    "    with open(outputDir+docID+\".txt\", \"w\") as opf:\n",
    "        tfidf_list = sorted(tfidf_info.items(), key=lambda x : x)\n",
    "        for item in tfidf_list:\n",
    "            index = str(item[0])\n",
    "            tfidf = str(item[1])\n",
    "            opf.write(index +\" \"+tfidf + \"\\n\")\n",
    "        \n",
    "        opf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructTFIDFVectors(dataDir, outputDir=None):\n",
    "    print(\"Start constructing...\\n\")\n",
    "    \n",
    "    if outputDir == None: # default value\n",
    "        outputDir = \"Output/TFIDF/\"\n",
    "    \n",
    "    if not os.path.isdir(outputDir): os.makedirs(outputDir) # check outputDir exist.\n",
    "    \n",
    "    dictionary = dict() # total term Dictionary\n",
    "    tfPool = dict()\n",
    "\n",
    "    fileList = listFiles(dataDir)\n",
    "    for file in fileList:\n",
    "        if(file != \".DS_Store\"): ### this line is for macOS, have to avoid this file\n",
    "            fileName = file.split('.')[0] # get only number\n",
    "            terms = getTermsDictFromDoc(dataDir + file)\n",
    "            tfPool[fileName] = terms # update TF pool\n",
    "\n",
    "            for key, value in terms.items(): # update Document Frequency(i.e., DF)\n",
    "                if key in dictionary:\n",
    "                    dictionary[key] += 1\n",
    "                else:\n",
    "                    dictionary[key] = 1\n",
    "\n",
    "    sortedDictionary = sortDictionary(dictionary) # sort the dictionary and change to list.\n",
    "    saveDictionary(sortedDictionary, outputDir) # save the dictionary to outputDir\n",
    "    dictionaryDict = transformDictionaryListToDict(sortedDictionary) # transform the dictionary to dict type\n",
    "    docTotalNumbers = len(fileList) # get total document number\n",
    "\n",
    "    for key, value in tfPool.items(): # key is docID, value is TF dict\n",
    "        doc_tfidf_Info = calculateTFIDF(value, dictionaryDict, docTotalNumbers) # a dict of document tf-idf information.\n",
    "        saveDocTFIDFInformation(key, doc_tfidf_Info, outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate and return the cosine similarity\n",
    "def cosine(documentX, documentY):\n",
    "    with open(documentX, \"r\") as docXHandle:\n",
    "        docX = docXHandle.readlines()\n",
    "    docX = [x.strip() for x in docX]\n",
    "    with open(documentY, \"r\") as docYHandle:\n",
    "        docY = docYHandle.readlines()\n",
    "    docY = [x.strip() for x in docY]\n",
    "    \n",
    "    docX_dict = dict()\n",
    "    for item in docX:\n",
    "        infos = item.split(' ')\n",
    "        termIdx = int(infos[0])\n",
    "        tfidfValue = float(infos[1])\n",
    "        docX_dict[termIdx] = tfidfValue\n",
    "        \n",
    "    docY_dict = dict()\n",
    "    for item in docY:\n",
    "        infos = item.split(' ')\n",
    "        termIdx = int(infos[0])\n",
    "        tfidfValue = float(infos[1])\n",
    "        docY_dict[termIdx] = tfidfValue\n",
    "    \n",
    "    listX, listY = prepareVectorsForConsine(docX_dict, docY_dict)\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.spatial.distance as distance\n",
    "    if checkAllZero(listX) or checkAllZero(listY): # if one of two list is empty, then return 0 score.\n",
    "        return 0\n",
    "    \n",
    "    # create two array(using two list from two doc), and calculate the similarity score\n",
    "    else:\n",
    "        arrDocX = np.array(listX)\n",
    "        arrDocY = np.array(listY)\n",
    "        similarityScore = 1 - distance.cosine(arrDocX, arrDocY)\n",
    "        return similarityScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkAllZero(docList):\n",
    "    for entry in docList:\n",
    "        if entry != 0:\n",
    "            return False\n",
    "    return True # this should never occur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the two given doc vector, add 0 element if the term id doesn't in the given document vector.\n",
    "# it's a memory waste method, but it works.\n",
    "def prepareVectorsForConsine(docX_dict, docY_dict):\n",
    "    docXKey_list = sorted(docX_dict.keys(), key=lambda key : key)\n",
    "    docYKey_list = sorted(docY_dict.keys(), key=lambda key : key)\n",
    "    \n",
    "    xminIdx = docXKey_list[0]\n",
    "    yminIdx = docYKey_list[0]\n",
    "    xmaxIdx = docXKey_list[len(docXKey_list)-1]\n",
    "    ymaxIdx = docYKey_list[len(docYKey_list)-1]\n",
    "    \n",
    "    # get the range of two term id.\n",
    "    mini = -1\n",
    "    maxi = -1\n",
    "    mini = xminIdx if(xminIdx < yminIdx) else yminIdx # get minimum term id in two docs\n",
    "    maxi = xmaxIdx if(xmaxIdx > ymaxIdx) else ymaxIdx # get the maximum term id in two docs\n",
    "    \n",
    "    # create two list, if there is a record of given id(i.e., num) in doc, then use the record tf-idf\n",
    "    # else add 0 in list.\n",
    "    listX = []\n",
    "    listY = []\n",
    "    for num in range(mini, maxi+1):\n",
    "        if num in docX_dict:\n",
    "            listX.append(docX_dict[num])\n",
    "        else:\n",
    "            listX.append(0)\n",
    "            \n",
    "        if num in docY_dict:\n",
    "            listY.append(docY_dict[num])\n",
    "        else:\n",
    "            listY.append(0)\n",
    "    \n",
    "    return listX, listY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

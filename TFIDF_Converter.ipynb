{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 先抓每篇文章的terms\n",
    "2. 把每篇文章的terms frequency(TF)偷記下來後面用\n",
    "3. 把所有Terms存在一個大Dict\n",
    "4. 大Dict裡面要有index, term內容, document frequency(DF)\n",
    "5. 弄consine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run TextPRocessor.ipynb\n",
    "\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputDir = \"Output/\"\n",
    "dicionary_OutputFileName = \"dictionary.txt\"\n",
    "\n",
    "if not os.path.isdir(outputDir): os.makedirs(outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listFiles(dir_path):\n",
    "    fList = []\n",
    "    for dirPath, dirName, fileNames in os.walk(dir_path):\n",
    "        fList.extend(fileNames)\n",
    "    return fList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save dictionary list to text file.\n",
    "def saveDictionary(dictionary_list):\n",
    "    \n",
    "    with open(outputDir+dicionary_OutputFileName, \"w\") as opf:\n",
    "        \n",
    "        for item in dictionary_list:\n",
    "            index = str(item[0])\n",
    "            term = item[1]\n",
    "            df = str(item[2])\n",
    "            # write to file\n",
    "            opf.write(index+\" \"+term+\" \"+df)\n",
    "            opf.write(\"\\n\")\n",
    "            \n",
    "        opf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort the dictionary by term(ascending order)\n",
    "# add the index into tuple\n",
    "\n",
    "def sortDictionary(dictionary_Dict):\n",
    "    tempList = sorted(dictionary_Dict.items(), key = lambda x : x[0])\n",
    "    index = 0\n",
    "    outputList = list()\n",
    "    for item in tempList:\n",
    "        term = item[0]\n",
    "        df = item[1]\n",
    "        outputList.append((index, term, df))\n",
    "        index+=1\n",
    "        \n",
    "    return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for using and efficient purpose, turn the list to dict type\n",
    "def transformDictionaryListToDict(dictionaryList):\n",
    "    outputDict = dict()\n",
    "    for item in dictionaryList:\n",
    "        index = item[0]\n",
    "        term = item[1]\n",
    "        df = item[2]\n",
    "        outputDict[term] = (index, df)\n",
    "    return outputDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateIDF(df, totalDocNumbers):\n",
    "    ratio = totalDocNumbers / df\n",
    "    return math.log10(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateTFIDF(documentTF_dict, dictionary_dict, totalDocNumbers):\n",
    "    outputDict = dict()\n",
    "    for term, termFrequency in documentTF_dict.items():\n",
    "        termObj_in_dictionary =  dictionary_dict[term]\n",
    "        termIndex = termObj_in_dictionary[0]\n",
    "        df = termObj_in_dictionary[1]\n",
    "        idf = calculateIDF(df, totalDocNumbers)\n",
    "        tfidf = termFrequency * idf\n",
    "        outputDict[termIndex] = tfidf\n",
    "    return outputDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveDocTFIDFInformation(docID, tfidf_info):\n",
    "    with open(outputDir+docID+\".txt\", \"w\") as opf:\n",
    "        tfidf_list = sorted(tfidf_info.items(), key=lambda x : x)\n",
    "        for item in tfidf_list:\n",
    "            index = str(item[0])\n",
    "            tfidf = str(item[1])\n",
    "            opf.write(index +\" \"+tfidf + \"\\n\")\n",
    "        \n",
    "        opf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructTFIDFVectors(dataDir):\n",
    "    dictionary = dict() # total term Dictionary\n",
    "    tfPool = dict()\n",
    "\n",
    "    fileList = listFiles(dataDir)\n",
    "    for file in fileList:\n",
    "        fileName = file.split('.')[0] # get only number\n",
    "        terms = getTermsDict(dataDir + file)\n",
    "        tfPool[fileName] = terms # update TF pool\n",
    "\n",
    "        for key, value in terms.items(): # update Document Frequency(i.e., DF)\n",
    "            if key in dictionary:\n",
    "                dictionary[key] += 1\n",
    "            else:\n",
    "                dictionary[key] = 1\n",
    "\n",
    "    sortedDictionary = sortDictionary(dictionary) # sort and change to list.\n",
    "    saveDictionary(sortedDictionary)\n",
    "    dictionaryDict = transformDictionaryListToDict(sortedDictionary)\n",
    "    docTotalNumbers = len(fileList) # get total document number\n",
    "\n",
    "    for key, value in tfPool.items(): # key is docID, value is TF dict\n",
    "        doc_tfidf_Info = calculateTFIDF(value, dictionaryDict, docTotalNumbers) # a dict of document tf-idf information.\n",
    "        saveDocTFIDFInformation(key, doc_tfidf_Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine(documentX, documentY):\n",
    "    with open(documentX, \"r\") as docXHandle:\n",
    "        docX = docXHandle.readlines()\n",
    "    docX = [x.strip() for x in docX]\n",
    "    with open(documentY, \"r\") as docYHandle:\n",
    "        docY = docYHandle.readlines()\n",
    "    docY = [x.strip() for x in docY]\n",
    "    \n",
    "    docX_dict = dict()\n",
    "    for item in docX:\n",
    "        infos = item.split(' ')\n",
    "        docX_dict[int(infos[0])] = float(infos[1])\n",
    "        \n",
    "    docY_dict = dict()\n",
    "    for item in docY:\n",
    "        infos = item.split(' ')\n",
    "        docY_dict[int(infos[0])] = float(infos[1])\n",
    "    \n",
    "    listX, listY = checkEmptyEntry(docX_dict, docY_dict)\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.spatial.distance as distance\n",
    "    if checkAllZero(listX) or checkAllZero(listY):\n",
    "        return 0\n",
    "    else:\n",
    "        arrDocX = np.array(listX)\n",
    "        arrDocY = np.array(listY)\n",
    "        similarityScore = 1 - distance.cosine(arrDocX, arrDocY)\n",
    "        return similarityScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAllZero(docList):\n",
    "    for entry in docList:\n",
    "        if entry != 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEmptyEntry(docX_dict, docY_dict):\n",
    "    docXKey_list = sorted(docX_dict.keys(), key=lambda key : key)\n",
    "    docYKey_list = sorted(docY_dict.keys(), key=lambda key : key)\n",
    "    \n",
    "    xminIdx = docXKey_list[0]\n",
    "    yminIdx = docYKey_list[0]\n",
    "    xmaxIdx = docXKey_list[len(docXKey_list)-1]\n",
    "    ymaxIdx = docYKey_list[len(docYKey_list)-1]\n",
    "    mini = -1\n",
    "    maxi = -1\n",
    "    mini = xminIdx if(xminIdx < yminIdx) else yminIdx\n",
    "    maxi = xmaxIdx if(xmaxIdx > ymaxIdx) else ymaxIdx\n",
    "    listX = []\n",
    "    listY = []\n",
    "    for num in range(mini, maxi+1):\n",
    "        if num in docX_dict:\n",
    "            listX.append(docX_dict[num])\n",
    "        else:\n",
    "            listX.append(0)\n",
    "            \n",
    "        if num in docY_dict:\n",
    "            listY.append(docY_dict[num])\n",
    "        else:\n",
    "            listY.append(0)\n",
    "    \n",
    "    return listX, listY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docX = \"Output/TFIDF/1.txt\"\n",
    "docY = \"Output/TFIDF/2.txt\"\n",
    "cosine(docX, docY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
